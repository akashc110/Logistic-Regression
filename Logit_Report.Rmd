---
title: "Logistic Regression"
author: "AC"
date: "July 19, 2016"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Logistic Regression - Introduction
Logistic regression is a predictive analysis approach conducted when the dependent variable is dichotomous (binary). It is used to describe data and to explain the relationship between one dependent binary variable and one or more metric independent variables.


## Logistic Regression - Basic Equation
The logistic function can be understood simply as finding the $\beta$  parameters that best fit:
   
  y = 1 if $\beta_0 + \beta_1x + \epsilon$ > 0

  y = 0
where $\epsilon$ is an error distributed by the standard logistic distribution. (If standard normal distribution is used instead, it is a probit regression.)

![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/600px-Logistic-curve.svg.png)

# Figure 1. The standard logistic function $\sigma(t)$ (where $\sigma(t) \in (0,1)$) 

The logistic function $\sigma(t)$ is defined as follows:

$\sigma(t) = \frac{1}{1 + e^{-t}}$

In our case, $t = \beta_0 + \beta_1x$.

So the logistic function can now be written as:

$\ F(x) = \frac{1}{1 + e^{-{(\beta_0 + \beta_1x)}}}$


##Logistic Regression - Assumptions
The major assumptions are:

1. The outcomes must be discrete i.e.the dependent variable should be binary in nature (eg. presence vs absence).

2. There should be no outliers in the data, this can be done by converting the continuous predictors to standardized z scores and remove values below -3.29 or greater than 3.29.

3. There should be no high intercorrelations (multicollinearity) among the predictors (Correlation coefficients should be less than 0.9).

##Sample Example

```{r}
rm(list = ls())

library(ggplot2)
library(aod)
library(Rcpp)

dat0 <- data.frame(read.csv("http://www.ats.ucla.edu/stat/data/binary.csv"))
head(dat0)
summary(dat0)

sapply(dat0, sd)

#table(dat0$admit,dat0$rank)
#For categorical data, looking at contingency table
xtabs(~ admit + rank, data = dat0)

#Using the logit model
dat0$rank <- as.factor(dat0$rank)

logit <- glm(admit ~ gre + gpa + rank, data = dat0, family = "binomial")
summary(logit)

#Obtaining confidence intervals using profiled log-liklihood
confint(logit)

#Obtaining confidence intervals using standard errors
confint.default(logit)

#Can test the overall effect of rank
wald.test(b = coef(logit), Sigma = vcov(logit), Terms = 4:6)

#Interpreting the odds ratios
exp(coef(logit))

#Interpreting the odds ratio and 95% CI
exp(cbind(OR = coef(logit), confint(logit)))

#Calculating the predicted probability of admission at each 
#value of rank, holding gre and gpa at their means.

dat1 <- with(dat0, data.frame(gre = mean(gre), gpa = mean(gpa),
             rank = factor(1:4)))
dat1

#Prediction

dat1$rankprob <- predict(logit, newdata = dat1, type = "response")
dat1

#Preparing data to plot 

dat2 <- with(dat0, 
             data.frame(gre = rep(seq(from = 200, to = 800, length.out = 100), 4),
             gpa = mean(gpa), rank = factor(rep(1:4, each = 100))))


dat3 <- cbind(dat2, predict(logit, newdata = dat2, type = "link", se = TRUE))
dat3 <- within(dat3, {
               PredictedProb <- plogis(fit)
               LL <- plogis(fit - (1.96*se.fit))
               UL <- plogis(fit + (1.96*se.fit))
})

head(dat3)

#Testing Model Fit

with(logit, null.deviance - deviance)
with(logit, df.null - df.residual)

#Evaluating p-value
with(logit, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))

#Log Liklihood
logLik(logit)

```

##Plots

The above result can be graphically shown as follows:

```{r}
ggplot(dat3, aes(x = gre, y = PredictedProb)) +
  geom_ribbon(aes(ymin = LL, ymax = UL, fill = rank), alpha = 0.2) +
  geom_line(aes(colour = rank), size = 1)

  

```


## References
1. R Data Analysis Examples: Logit Regression from <http://www.ats.ucla.edu/stat/r/dae/logit.htm>
2. Statistics Solutions <http://www.statisticssolutions.com/what-is-logistic-regression/>
3. Wikipedia <https://en.wikipedia.org/wiki/Logistic_regression>
